# -*- coding: utf-8 -*-
"""fake_news_detection

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ioGmHP2EWDN8rryjaxP1WCwi2deTTp5U

#Fake News Detection

Import libraries
"""

# Importing necessary libraries

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import PassiveAggressiveClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix

"""Load the dataset"""

# load the dataset

train_df = pd.read_csv('/content/train[1].csv')
train_df

"""Data Exploration"""

# Headings

train_df.head(15)

# Last rows

train_df.tail(15)

# Info

train_df.info()

# Describe

train_df.describe()

#Shape

train_df.shape

# getting labels

labels=train_df.Label
labels

# getting Statement

train_df['Statement'][2188]

# removing null values

train_df = train_df.dropna()
train_df

# data quality check

def data_qualityCheck():
    print("Checking data qualitites...")
    train_df.isnull().sum()
    train_df.info()
    print("check finished.")
data_qualityCheck()

"""**Data Visualization**"""

# Bar plot

plt.figure(figsize=(8, 6))
sb.countplot(x='Label', data=train_df)
plt.title('Distribution of Labels')
plt.xlabel('Label')
plt.ylabel('Count')
plt.show()

"""**Training the Dataset**"""

# Splitting data into features and labels

X = train_df['Statement']
y = train_df['Label']
X, y

# Initialize TF-IDF Vectorizer

tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)
tfidf_vectorizer

# Fit and transform the data

X_tfidf = tfidf_vectorizer.fit_transform(X)
X_tfidf

# Split the dataset into training and testing sets

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train, X_test, y_train, y_test

# Feature Engineering (TF-IDF Vectorization)

tfidf_matrix = tfidf_vectorizer.fit_transform(train_df['Statement'])

# Initialize Passive Aggressive Classifier

pac = PassiveAggressiveClassifier(max_iter=50)

# Train the model

pac.fit(tfidf_matrix, train_df['Label'])

# Predictions

y_pred = pac.predict(X_tfidf)
y_pred

# Model Evaluation

accuracy = accuracy_score(y, y_pred)
print(f'Accuracy: {accuracy:.2f}')

# Confusion Matrix

conf_matrix = confusion_matrix(y, y_pred)
print('Confusion Matrix:')
print(conf_matrix)

# Heatmap for confusion matrix

sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d', xticklabels=['FAKE Data', 'REAL Data'], yticklabels=['FAKE Data', 'REAL Data'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

# Function to predict if a statement is fake or real

def predict_statement(statement):
    statement_tfidf = tfidf_vectorizer.transform([statement])
    prediction = pac.predict(statement_tfidf)
    if prediction == 1:
        return "False"
    else:
        return "True"

# Output

Statement = "Study shows that eating apples can lower cholesterol."
prediction = predict_fake_or_real(statement)
print(f"The statement '{Statement}' is predicted as: {prediction}")

"""Conclusion and Insights:

1. Accuracy: 0.97
2. Confusion Matrix:
[[4348  140]
 [ 126 5626]]
3. Output: The statement 'Study shows that eating apples can lower cholesterol.' is predicted as: True
"""